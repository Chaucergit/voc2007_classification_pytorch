"C:\Program Files\Anaconda3\python.exe" D:/¸Ä½ø/PascalClassificationPytorch-master/PascalTrain.py
Using GPU 1
Start training: lr 0.001000, batch size 8
Checkpoint: checkpoints/
Learning Rate 0.001000
[1/160] 0), Loss: 0.696, mAP 20.20%
[1/160] 100), Loss: 0.303, mAP 46.41%
[1/160] 200), Loss: 0.265, mAP 49.22%
[1/160] 300), Loss: 0.245, mAP 45.56%
[1/160] 400), Loss: 0.205, mAP 48.66%
[1/160] 500), Loss: 0.248, mAP 55.32%
[1/160] 600), Loss: 0.208, mAP 54.20%
Saved: checkpoints/
TESTING: 627), mAP 63.90%
Learning Rate 0.001000
[2/160] 700), Loss: 0.235, mAP 61.10%
[2/160] 800), Loss: 0.172, mAP 63.35%
[2/160] 900), Loss: 0.163, mAP 66.39%
[2/160] 1000), Loss: 0.173, mAP 68.23%
[2/160] 1100), Loss: 0.175, mAP 73.53%
[2/160] 1200), Loss: 0.189, mAP 70.88%
Learning Rate 0.001000
[3/160] 1300), Loss: 0.135, mAP 73.62%
[3/160] 1400), Loss: 0.163, mAP 76.28%
[3/160] 1500), Loss: 0.144, mAP 75.44%
[3/160] 1600), Loss: 0.173, mAP 74.59%
[3/160] 1700), Loss: 0.137, mAP 77.05%
[3/160] 1800), Loss: 0.261, mAP 77.15%
Learning Rate 0.001000
[4/160] 1900), Loss: 0.117, mAP 70.96%
[4/160] 2000), Loss: 0.103, mAP 77.84%
[4/160] 2100), Loss: 0.147, mAP 81.63%
[4/160] 2200), Loss: 0.089, mAP 82.58%
[4/160] 2300), Loss: 0.124, mAP 78.12%
[4/160] 2400), Loss: 0.110, mAP 77.65%
[4/160] 2500), Loss: 0.099, mAP 79.30%
Learning Rate 0.001000
[5/160] 2600), Loss: 0.115, mAP 80.79%
[5/160] 2700), Loss: 0.133, mAP 82.71%
[5/160] 2800), Loss: 0.103, mAP 81.60%
[5/160] 2900), Loss: 0.101, mAP 79.44%
[5/160] 3000), Loss: 0.125, mAP 83.37%
[5/160] 3100), Loss: 0.095, mAP 82.78%
Learning Rate 0.001000
[6/160] 3200), Loss: 0.120, mAP 80.74%
[6/160] 3300), Loss: 0.150, mAP 81.07%
[6/160] 3400), Loss: 0.123, mAP 83.56%
[6/160] 3500), Loss: 0.237, mAP 85.13%
[6/160] 3600), Loss: 0.136, mAP 85.34%
[6/160] 3700), Loss: 0.154, mAP 80.88%
Saved: checkpoints/
TESTING: 3762), mAP 91.48%
Learning Rate 0.001000
[7/160] 3800), Loss: 0.122, mAP 82.80%
[7/160] 3900), Loss: 0.136, mAP 84.86%
[7/160] 4000), Loss: 0.107, mAP 81.29%
[7/160] 4100), Loss: 0.115, mAP 86.05%
[7/160] 4200), Loss: 0.124, mAP 83.50%
[7/160] 4300), Loss: 0.117, mAP 82.03%
Learning Rate 0.001000
[8/160] 4400), Loss: 0.083, mAP 86.28%
[8/160] 4500), Loss: 0.094, mAP 84.11%
[8/160] 4600), Loss: 0.081, mAP 87.08%
[8/160] 4700), Loss: 0.143, mAP 84.61%
[8/160] 4800), Loss: 0.115, mAP 82.69%
[8/160] 4900), Loss: 0.082, mAP 87.64%
[8/160] 5000), Loss: 0.074, mAP 85.75%
Learning Rate 0.001000
[9/160] 5100), Loss: 0.123, mAP 81.26%
[9/160] 5200), Loss: 0.097, mAP 84.56%
[9/160] 5300), Loss: 0.140, mAP 80.70%
[9/160] 5400), Loss: 0.081, mAP 88.19%
[9/160] 5500), Loss: 0.106, mAP 88.45%
[9/160] 5600), Loss: 0.134, mAP 84.86%
Learning Rate 0.001000
[10/160] 5700), Loss: 0.118, mAP 88.81%
[10/160] 5800), Loss: 0.136, mAP 86.53%
[10/160] 5900), Loss: 0.054, mAP 85.80%
[10/160] 6000), Loss: 0.116, mAP 87.06%
[10/160] 6100), Loss: 0.165, mAP 82.98%
[10/160] 6200), Loss: 0.058, mAP 87.42%
Learning Rate 0.001000
[11/160] 6300), Loss: 0.084, mAP 86.71%
[11/160] 6400), Loss: 0.100, mAP 86.94%
[11/160] 6500), Loss: 0.103, mAP 81.77%
[11/160] 6600), Loss: 0.116, mAP 87.52%
[11/160] 6700), Loss: 0.132, mAP 87.07%
[11/160] 6800), Loss: 0.099, mAP 86.84%
Saved: checkpoints/
TESTING: 6897), mAP 93.65%
Learning Rate 0.001000
[12/160] 6900), Loss: 0.061, mAP 90.32%
[12/160] 7000), Loss: 0.121, mAP 88.93%
[12/160] 7100), Loss: 0.105, mAP 86.06%
[12/160] 7200), Loss: 0.124, mAP 82.97%
[12/160] 7300), Loss: 0.066, mAP 89.67%
[12/160] 7400), Loss: 0.088, mAP 86.92%
[12/160] 7500), Loss: 0.118, mAP 86.73%
Learning Rate 0.001000
[13/160] 7600), Loss: 0.087, mAP 90.09%
[13/160] 7700), Loss: 0.114, mAP 86.27%
[13/160] 7800), Loss: 0.110, mAP 87.32%
[13/160] 7900), Loss: 0.068, mAP 86.62%
[13/160] 8000), Loss: 0.064, mAP 89.60%
[13/160] 8100), Loss: 0.084, mAP 88.33%
Learning Rate 0.001000
[14/160] 8200), Loss: 0.127, mAP 85.09%
[14/160] 8300), Loss: 0.120, mAP 87.87%
[14/160] 8400), Loss: 0.149, mAP 89.33%
[14/160] 8500), Loss: 0.090, mAP 87.35%
[14/160] 8600), Loss: 0.116, mAP 87.21%
[14/160] 8700), Loss: 0.102, mAP 85.68%
Learning Rate 0.001000
[15/160] 8800), Loss: 0.055, mAP 87.79%
[15/160] 8900), Loss: 0.097, mAP 89.00%
[15/160] 9000), Loss: 0.080, mAP 88.72%
[15/160] 9100), Loss: 0.076, mAP 87.67%
[15/160] 9200), Loss: 0.126, mAP 87.42%
[15/160] 9300), Loss: 0.101, mAP 87.83%
[15/160] 9400), Loss: 0.047, mAP 89.64%
Learning Rate 0.001000
[16/160] 9500), Loss: 0.060, mAP 88.86%
[16/160] 9600), Loss: 0.094, mAP 90.58%
[16/160] 9700), Loss: 0.060, mAP 87.02%
[16/160] 9800), Loss: 0.072, mAP 89.08%
[16/160] 9900), Loss: 0.113, mAP 89.08%
[16/160] 10000), Loss: 0.103, mAP 88.05%
Saved: checkpoints/
TESTING: 10032), mAP 94.26%
Learning Rate 0.001000
[17/160] 10100), Loss: 0.067, mAP 87.44%
[17/160] 10200), Loss: 0.073, mAP 89.51%
[17/160] 10300), Loss: 0.105, mAP 88.56%
[17/160] 10400), Loss: 0.103, mAP 91.07%
[17/160] 10500), Loss: 0.113, mAP 91.14%
[17/160] 10600), Loss: 0.110, mAP 89.55%
Learning Rate 0.001000
[18/160] 10700), Loss: 0.082, mAP 88.02%
[18/160] 10800), Loss: 0.076, mAP 89.91%
[18/160] 10900), Loss: 0.097, mAP 87.77%
[18/160] 11000), Loss: 0.086, mAP 89.32%
[18/160] 11100), Loss: 0.095, mAP 88.65%
[18/160] 11200), Loss: 0.116, mAP 87.96%
Learning Rate 0.001000
[19/160] 11300), Loss: 0.069, mAP 88.74%
[19/160] 11400), Loss: 0.051, mAP 91.10%
[19/160] 11500), Loss: 0.132, mAP 90.37%
[19/160] 11600), Loss: 0.072, mAP 90.42%
[19/160] 11700), Loss: 0.067, mAP 87.17%
[19/160] 11800), Loss: 0.090, mAP 86.91%
[19/160] 11900), Loss: 0.076, mAP 91.60%
Learning Rate 0.001000
[20/160] 12000), Loss: 0.081, mAP 90.59%
[20/160] 12100), Loss: 0.061, mAP 88.37%
[20/160] 12200), Loss: 0.073, mAP 91.43%
[20/160] 12300), Loss: 0.077, mAP 87.78%
[20/160] 12400), Loss: 0.184, mAP 89.68%
[20/160] 12500), Loss: 0.065, mAP 91.57%
Learning Rate 0.001000
[21/160] 12600), Loss: 0.086, mAP 89.51%
[21/160] 12700), Loss: 0.081, mAP 92.30%
[21/160] 12800), Loss: 0.034, mAP 91.04%
[21/160] 12900), Loss: 0.053, mAP 92.11%
[21/160] 13000), Loss: 0.111, mAP 91.39%
[21/160] 13100), Loss: 0.109, mAP 87.43%
Saved: checkpoints/
TESTING: 13167), mAP 94.54%
Learning Rate 0.001000
[22/160] 13200), Loss: 0.061, mAP 89.53%
[22/160] 13300), Loss: 0.094, mAP 88.71%
[22/160] 13400), Loss: 0.047, mAP 89.90%
[22/160] 13500), Loss: 0.107, mAP 89.65%
[22/160] 13600), Loss: 0.150, mAP 90.16%
[22/160] 13700), Loss: 0.079, mAP 87.26%
Learning Rate 0.001000
[23/160] 13800), Loss: 0.101, mAP 86.68%
[23/160] 13900), Loss: 0.105, mAP 92.00%
[23/160] 14000), Loss: 0.049, mAP 91.77%
[23/160] 14100), Loss: 0.065, mAP 88.61%
[23/160] 14200), Loss: 0.079, mAP 89.97%
[23/160] 14300), Loss: 0.100, mAP 90.33%
[23/160] 14400), Loss: 0.164, mAP 90.47%
Learning Rate 0.001000
[24/160] 14500), Loss: 0.084, mAP 87.58%
[24/160] 14600), Loss: 0.075, mAP 91.93%
[24/160] 14700), Loss: 0.124, mAP 87.70%
[24/160] 14800), Loss: 0.116, mAP 90.52%
[24/160] 14900), Loss: 0.123, mAP 92.04%
[24/160] 15000), Loss: 0.082, mAP 89.73%
Learning Rate 0.001000
[25/160] 15100), Loss: 0.124, mAP 91.33%
[25/160] 15200), Loss: 0.119, mAP 88.12%
[25/160] 15300), Loss: 0.165, mAP 89.35%
[25/160] 15400), Loss: 0.048, mAP 89.74%
[25/160] 15500), Loss: 0.055, mAP 90.68%
[25/160] 15600), Loss: 0.046, mAP 93.26%
Learning Rate 0.001000
[26/160] 15700), Loss: 0.101, mAP 92.58%
[26/160] 15800), Loss: 0.108, mAP 92.58%
[26/160] 15900), Loss: 0.062, mAP 87.39%
[26/160] 16000), Loss: 0.084, mAP 91.72%
[26/160] 16100), Loss: 0.097, mAP 90.60%
[26/160] 16200), Loss: 0.043, mAP 87.88%
[26/160] 16300), Loss: 0.081, mAP 93.43%
Saved: checkpoints/
TESTING: 16302), mAP 94.64%
Learning Rate 0.001000
[27/160] 16400), Loss: 0.056, mAP 90.77%
[27/160] 16500), Loss: 0.143, mAP 89.78%
[27/160] 16600), Loss: 0.079, mAP 90.60%
[27/160] 16700), Loss: 0.100, mAP 89.70%
[27/160] 16800), Loss: 0.079, mAP 91.80%
[27/160] 16900), Loss: 0.062, mAP 90.56%
Learning Rate 0.001000
[28/160] 17000), Loss: 0.029, mAP 90.05%
[28/160] 17100), Loss: 0.082, mAP 93.98%
[28/160] 17200), Loss: 0.045, mAP 88.99%
[28/160] 17300), Loss: 0.055, mAP 90.83%
[28/160] 17400), Loss: 0.066, mAP 86.64%
[28/160] 17500), Loss: 0.086, mAP 90.18%
Learning Rate 0.001000
[29/160] 17600), Loss: 0.089, mAP 92.84%
[29/160] 17700), Loss: 0.067, mAP 89.00%
[29/160] 17800), Loss: 0.097, mAP 91.40%
[29/160] 17900), Loss: 0.063, mAP 90.94%
[29/160] 18000), Loss: 0.062, mAP 92.74%
[29/160] 18100), Loss: 0.052, mAP 92.39%
Learning Rate 0.001000
[30/160] 18200), Loss: 0.058, mAP 89.24%
[30/160] 18300), Loss: 0.079, mAP 88.46%
[30/160] 18400), Loss: 0.112, mAP 89.20%
[30/160] 18500), Loss: 0.095, mAP 90.19%
[30/160] 18600), Loss: 0.061, mAP 91.64%
[30/160] 18700), Loss: 0.127, mAP 88.64%
[30/160] 18800), Loss: 0.047, mAP 92.55%
Learning Rate 0.001000
[31/160] 18900), Loss: 0.089, mAP 89.26%
[31/160] 19000), Loss: 0.133, mAP 93.01%
[31/160] 19100), Loss: 0.086, mAP 90.69%
[31/160] 19200), Loss: 0.101, mAP 90.78%
[31/160] 19300), Loss: 0.051, mAP 90.14%
[31/160] 19400), Loss: 0.049, mAP 91.37%
Saved: checkpoints/
TESTING: 19437), mAP 94.91%
Learning Rate 0.001000
[32/160] 19500), Loss: 0.104, mAP 91.12%
[32/160] 19600), Loss: 0.044, mAP 91.01%
[32/160] 19700), Loss: 0.099, mAP 91.07%
[32/160] 19800), Loss: 0.077, mAP 90.39%
[32/160] 19900), Loss: 0.118, mAP 91.43%
[32/160] 20000), Loss: 0.087, mAP 88.41%
Learning Rate 0.001000
[33/160] 20100), Loss: 0.118, mAP 92.45%
[33/160] 20200), Loss: 0.052, mAP 92.77%
[33/160] 20300), Loss: 0.122, mAP 92.25%
[33/160] 20400), Loss: 0.124, mAP 91.63%
[33/160] 20500), Loss: 0.098, mAP 90.98%
[33/160] 20600), Loss: 0.070, mAP 89.66%
Learning Rate 0.001000
[34/160] 20700), Loss: 0.074, mAP 90.27%
[34/160] 20800), Loss: 0.060, mAP 93.33%
[34/160] 20900), Loss: 0.084, mAP 93.27%
[34/160] 21000), Loss: 0.053, mAP 92.66%
[34/160] 21100), Loss: 0.039, mAP 94.73%
[34/160] 21200), Loss: 0.060, mAP 92.66%
[34/160] 21300), Loss: 0.091, mAP 92.10%
Learning Rate 0.001000
[35/160] 21400), Loss: 0.080, mAP 94.01%
[35/160] 21500), Loss: 0.062, mAP 92.49%
[35/160] 21600), Loss: 0.073, mAP 92.05%
[35/160] 21700), Loss: 0.153, mAP 92.69%
[35/160] 21800), Loss: 0.067, mAP 90.16%
[35/160] 21900), Loss: 0.039, mAP 93.75%
Learning Rate 0.001000
[36/160] 22000), Loss: 0.050, mAP 93.44%
[36/160] 22100), Loss: 0.091, mAP 93.60%
[36/160] 22200), Loss: 0.054, mAP 93.09%
[36/160] 22300), Loss: 0.066, mAP 89.72%
[36/160] 22400), Loss: 0.052, mAP 92.55%
[36/160] 22500), Loss: 0.053, mAP 93.33%
Saved: checkpoints/
TESTING: 22572), mAP 94.87%
Learning Rate 0.001000
[37/160] 22600), Loss: 0.060, mAP 88.61%
[37/160] 22700), Loss: 0.124, mAP 93.30%
[37/160] 22800), Loss: 0.103, mAP 90.12%
[37/160] 22900), Loss: 0.100, mAP 91.58%
[37/160] 23000), Loss: 0.042, mAP 95.04%
[37/160] 23100), Loss: 0.070, mAP 90.54%
Learning Rate 0.001000
[38/160] 23200), Loss: 0.123, mAP 81.98%
[38/160] 23300), Loss: 0.081, mAP 92.40%
[38/160] 23400), Loss: 0.043, mAP 91.54%
[38/160] 23500), Loss: 0.046, mAP 94.35%
[38/160] 23600), Loss: 0.062, mAP 90.52%
[38/160] 23700), Loss: 0.082, mAP 93.04%
[38/160] 23800), Loss: 0.054, mAP 92.92%
Learning Rate 0.001000
[39/160] 23900), Loss: 0.062, mAP 93.08%
[39/160] 24000), Loss: 0.095, mAP 91.76%
[39/160] 24100), Loss: 0.075, mAP 90.99%
[39/160] 24200), Loss: 0.125, mAP 90.88%
[39/160] 24300), Loss: 0.106, mAP 93.70%
[39/160] 24400), Loss: 0.052, mAP 93.89%
Learning Rate 0.001000
[40/160] 24500), Loss: 0.061, mAP 92.50%
[40/160] 24600), Loss: 0.091, mAP 94.68%
[40/160] 24700), Loss: 0.052, mAP 93.75%
[40/160] 24800), Loss: 0.177, mAP 94.28%
[40/160] 24900), Loss: 0.100, mAP 93.81%
[40/160] 25000), Loss: 0.064, mAP 91.05%
Learning Rate 0.001000
[41/160] 25100), Loss: 0.047, mAP 91.35%
[41/160] 25200), Loss: 0.129, mAP 94.33%
[41/160] 25300), Loss: 0.103, mAP 90.61%
[41/160] 25400), Loss: 0.052, mAP 93.51%
[41/160] 25500), Loss: 0.047, mAP 91.84%
[41/160] 25600), Loss: 0.073, mAP 94.80%
[41/160] 25700), Loss: 0.080, mAP 95.08%
Saved: checkpoints/
TESTING: 25707), mAP 94.94%
Learning Rate 0.001000
[42/160] 25800), Loss: 0.084, mAP 91.36%
[42/160] 25900), Loss: 0.126, mAP 92.02%
[42/160] 26000), Loss: 0.104, mAP 92.97%
[42/160] 26100), Loss: 0.053, mAP 91.63%
[42/160] 26200), Loss: 0.057, mAP 92.17%
[42/160] 26300), Loss: 0.036, mAP 93.19%
Learning Rate 0.001000
[43/160] 26400), Loss: 0.034, mAP 94.38%
[43/160] 26500), Loss: 0.065, mAP 96.42%
[43/160] 26600), Loss: 0.047, mAP 91.92%
[43/160] 26700), Loss: 0.054, mAP 91.15%
[43/160] 26800), Loss: 0.080, mAP 94.99%
[43/160] 26900), Loss: 0.057, mAP 92.91%
Learning Rate 0.001000
[44/160] 27000), Loss: 0.032, mAP 92.16%
[44/160] 27100), Loss: 0.122, mAP 92.06%
[44/160] 27200), Loss: 0.062, mAP 93.74%
[44/160] 27300), Loss: 0.042, mAP 93.97%
[44/160] 27400), Loss: 0.067, mAP 95.33%
[44/160] 27500), Loss: 0.042, mAP 92.52%
Learning Rate 0.001000
[45/160] 27600), Loss: 0.058, mAP 92.72%
[45/160] 27700), Loss: 0.050, mAP 92.23%
[45/160] 27800), Loss: 0.040, mAP 92.97%
[45/160] 27900), Loss: 0.030, mAP 93.35%
[45/160] 28000), Loss: 0.075, mAP 92.72%
[45/160] 28100), Loss: 0.088, mAP 91.88%
[45/160] 28200), Loss: 0.043, mAP 92.26%
Learning Rate 0.001000
[46/160] 28300), Loss: 0.086, mAP 92.53%
[46/160] 28400), Loss: 0.104, mAP 93.06%
[46/160] 28500), Loss: 0.049, mAP 94.37%
[46/160] 28600), Loss: 0.086, mAP 91.86%
[46/160] 28700), Loss: 0.060, mAP 93.72%
[46/160] 28800), Loss: 0.063, mAP 93.23%
Saved: checkpoints/
TESTING: 28842), mAP 95.08%
Learning Rate 0.001000
[47/160] 28900), Loss: 0.068, mAP 90.33%
[47/160] 29000), Loss: 0.088, mAP 92.08%
[47/160] 29100), Loss: 0.043, mAP 94.49%
[47/160] 29200), Loss: 0.066, mAP 92.28%
[47/160] 29300), Loss: 0.079, mAP 89.53%
[47/160] 29400), Loss: 0.101, mAP 91.22%
Learning Rate 0.001000
[48/160] 29500), Loss: 0.051, mAP 93.16%
[48/160] 29600), Loss: 0.070, mAP 92.49%
[48/160] 29700), Loss: 0.104, mAP 92.89%
[48/160] 29800), Loss: 0.055, mAP 93.76%
[48/160] 29900), Loss: 0.039, mAP 93.02%
[48/160] 30000), Loss: 0.076, mAP 94.27%
Learning Rate 0.001000
[49/160] 30100), Loss: 0.059, mAP 92.93%
[49/160] 30200), Loss: 0.036, mAP 95.28%
[49/160] 30300), Loss: 0.046, mAP 92.69%
[49/160] 30400), Loss: 0.090, mAP 95.13%
[49/160] 30500), Loss: 0.089, mAP 93.15%
[49/160] 30600), Loss: 0.053, mAP 95.05%
[49/160] 30700), Loss: 0.051, mAP 93.66%
Learning Rate 0.001000
[50/160] 30800), Loss: 0.056, mAP 92.75%
[50/160] 30900), Loss: 0.049, mAP 92.10%
[50/160] 31000), Loss: 0.073, mAP 92.16%
[50/160] 31100), Loss: 0.042, mAP 93.49%
[50/160] 31200), Loss: 0.102, mAP 92.77%
[50/160] 31300), Loss: 0.034, mAP 94.99%
Learning Rate 0.001000
[51/160] 31400), Loss: 0.057, mAP 92.95%
[51/160] 31500), Loss: 0.020, mAP 91.21%
[51/160] 31600), Loss: 0.099, mAP 90.98%
[51/160] 31700), Loss: 0.128, mAP 93.16%
[51/160] 31800), Loss: 0.065, mAP 94.32%
[51/160] 31900), Loss: 0.090, mAP 92.46%
Saved: checkpoints/
TESTING: 31977), mAP 94.90%
Learning Rate 0.001000
[52/160] 32000), Loss: 0.110, mAP 93.41%
[52/160] 32100), Loss: 0.027, mAP 94.31%
[52/160] 32200), Loss: 0.073, mAP 96.56%
[52/160] 32300), Loss: 0.034, mAP 94.56%
[52/160] 32400), Loss: 0.091, mAP 93.45%
[52/160] 32500), Loss: 0.071, mAP 93.03%
[52/160] 32600), Loss: 0.052, mAP 94.41%
Learning Rate 0.001000
[53/160] 32700), Loss: 0.037, mAP 93.44%
[53/160] 32800), Loss: 0.039, mAP 95.22%
[53/160] 32900), Loss: 0.038, mAP 94.53%
[53/160] 33000), Loss: 0.032, mAP 94.81%
[53/160] 33100), Loss: 0.067, mAP 95.29%
[53/160] 33200), Loss: 0.074, mAP 92.91%
Learning Rate 0.001000
[54/160] 33300), Loss: 0.059, mAP 92.97%
[54/160] 33400), Loss: 0.063, mAP 89.94%
[54/160] 33500), Loss: 0.026, mAP 91.87%
[54/160] 33600), Loss: 0.073, mAP 92.78%
[54/160] 33700), Loss: 0.037, mAP 94.56%
[54/160] 33800), Loss: 0.060, mAP 94.06%
Learning Rate 0.001000
[55/160] 33900), Loss: 0.072, mAP 93.96%
[55/160] 34000), Loss: 0.050, mAP 94.10%
[55/160] 34100), Loss: 0.131, mAP 93.09%
[55/160] 34200), Loss: 0.056, mAP 91.90%
[55/160] 34300), Loss: 0.032, mAP 93.97%
[55/160] 34400), Loss: 0.089, mAP 91.78%
Learning Rate 0.001000
[56/160] 34500), Loss: 0.066, mAP 94.33%
[56/160] 34600), Loss: 0.091, mAP 93.15%
[56/160] 34700), Loss: 0.028, mAP 93.50%
[56/160] 34800), Loss: 0.064, mAP 95.17%
[56/160] 34900), Loss: 0.057, mAP 92.84%
[56/160] 35000), Loss: 0.062, mAP 93.25%
[56/160] 35100), Loss: 0.063, mAP 94.25%
Saved: checkpoints/
TESTING: 35112), mAP 94.78%
Learning Rate 0.001000
[57/160] 35200), Loss: 0.074, mAP 92.22%
[57/160] 35300), Loss: 0.034, mAP 94.50%
[57/160] 35400), Loss: 0.097, mAP 92.32%
[57/160] 35500), Loss: 0.051, mAP 94.68%
[57/160] 35600), Loss: 0.024, mAP 93.99%
[57/160] 35700), Loss: 0.068, mAP 93.62%
Learning Rate 0.001000
[58/160] 35800), Loss: 0.058, mAP 96.13%
[58/160] 35900), Loss: 0.050, mAP 93.89%
[58/160] 36000), Loss: 0.113, mAP 93.39%
[58/160] 36100), Loss: 0.027, mAP 93.03%
[58/160] 36200), Loss: 0.051, mAP 93.49%
[58/160] 36300), Loss: 0.108, mAP 92.35%
Learning Rate 0.001000
[59/160] 36400), Loss: 0.101, mAP 93.30%
[59/160] 36500), Loss: 0.085, mAP 95.01%
[59/160] 36600), Loss: 0.077, mAP 92.12%
[59/160] 36700), Loss: 0.079, mAP 95.60%
[59/160] 36800), Loss: 0.048, mAP 95.58%
[59/160] 36900), Loss: 0.043, mAP 95.72%
Learning Rate 0.001000
[60/160] 37000), Loss: 0.024, mAP 92.15%
[60/160] 37100), Loss: 0.066, mAP 91.41%
[60/160] 37200), Loss: 0.053, mAP 96.76%
[60/160] 37300), Loss: 0.065, mAP 92.96%
[60/160] 37400), Loss: 0.014, mAP 93.53%
[60/160] 37500), Loss: 0.067, mAP 94.71%
[60/160] 37600), Loss: 0.051, mAP 94.81%
Learning Rate 0.001000
[61/160] 37700), Loss: 0.061, mAP 96.67%
[61/160] 37800), Loss: 0.036, mAP 93.88%
[61/160] 37900), Loss: 0.078, mAP 92.59%
[61/160] 38000), Loss: 0.060, mAP 93.00%
[61/160] 38100), Loss: 0.082, mAP 94.87%
[61/160] 38200), Loss: 0.079, mAP 92.51%
Saved: checkpoints/
TESTING: 38247), mAP 94.78%
Learning Rate 0.001000
[62/160] 38300), Loss: 0.063, mAP 94.30%
[62/160] 38400), Loss: 0.036, mAP 95.02%
[62/160] 38500), Loss: 0.057, mAP 94.20%
[62/160] 38600), Loss: 0.032, mAP 93.58%
[62/160] 38700), Loss: 0.046, mAP 94.11%
[62/160] 38800), Loss: 0.070, mAP 95.56%
Learning Rate 0.001000
[63/160] 38900), Loss: 0.039, mAP 94.94%
[63/160] 39000), Loss: 0.089, mAP 95.38%
[63/160] 39100), Loss: 0.042, mAP 95.44%
[63/160] 39200), Loss: 0.031, mAP 93.66%
[63/160] 39300), Loss: 0.018, mAP 95.58%
[63/160] 39400), Loss: 0.028, mAP 94.20%
[63/160] 39500), Loss: 0.115, mAP 89.15%
Learning Rate 0.001000
[64/160] 39600), Loss: 0.055, mAP 95.60%
[64/160] 39700), Loss: 0.042, mAP 94.75%
[64/160] 39800), Loss: 0.068, mAP 96.64%
[64/160] 39900), Loss: 0.059, mAP 95.59%
[64/160] 40000), Loss: 0.045, mAP 95.42%
[64/160] 40100), Loss: 0.039, mAP 93.51%
Learning Rate 0.001000
[65/160] 40200), Loss: 0.051, mAP 92.59%
[65/160] 40300), Loss: 0.072, mAP 93.92%
[65/160] 40400), Loss: 0.060, mAP 93.94%
[65/160] 40500), Loss: 0.058, mAP 97.52%
[65/160] 40600), Loss: 0.049, mAP 94.49%
[65/160] 40700), Loss: 0.077, mAP 93.06%
Learning Rate 0.001000
[66/160] 40800), Loss: 0.044, mAP 93.70%
[66/160] 40900), Loss: 0.051, mAP 93.03%
[66/160] 41000), Loss: 0.081, mAP 94.92%
[66/160] 41100), Loss: 0.033, mAP 94.40%
[66/160] 41200), Loss: 0.071, mAP 94.78%
[66/160] 41300), Loss: 0.083, mAP 94.65%
Saved: checkpoints/
TESTING: 41382), mAP 94.99%
Learning Rate 0.001000
[67/160] 41400), Loss: 0.028, mAP 96.26%
[67/160] 41500), Loss: 0.053, mAP 94.03%
[67/160] 41600), Loss: 0.032, mAP 95.31%
[67/160] 41700), Loss: 0.048, mAP 94.37%
[67/160] 41800), Loss: 0.079, mAP 96.84%
[67/160] 41900), Loss: 0.028, mAP 95.42%
[67/160] 42000), Loss: 0.043, mAP 94.24%
Learning Rate 0.001000
[68/160] 42100), Loss: 0.034, mAP 95.91%
[68/160] 42200), Loss: 0.054, mAP 94.04%
[68/160] 42300), Loss: 0.084, mAP 93.71%
[68/160] 42400), Loss: 0.070, mAP 95.82%
[68/160] 42500), Loss: 0.032, mAP 95.35%
[68/160] 42600), Loss: 0.103, mAP 94.19%
Learning Rate 0.001000
[69/160] 42700), Loss: 0.046, mAP 94.28%
[69/160] 42800), Loss: 0.037, mAP 94.04%
[69/160] 42900), Loss: 0.042, mAP 94.74%
[69/160] 43000), Loss: 0.081, mAP 93.20%
[69/160] 43100), Loss: 0.164, mAP 94.21%
[69/160] 43200), Loss: 0.030, mAP 95.78%
Learning Rate 0.001000
[70/160] 43300), Loss: 0.078, mAP 93.07%
[70/160] 43400), Loss: 0.031, mAP 95.14%
[70/160] 43500), Loss: 0.052, mAP 95.26%
[70/160] 43600), Loss: 0.069, mAP 96.30%
[70/160] 43700), Loss: 0.069, mAP 92.93%
[70/160] 43800), Loss: 0.054, mAP 96.23%
Learning Rate 0.001000
[71/160] 43900), Loss: 0.062, mAP 94.86%
[71/160] 44000), Loss: 0.060, mAP 94.11%
[71/160] 44100), Loss: 0.025, mAP 92.94%
[71/160] 44200), Loss: 0.086, mAP 93.81%
[71/160] 44300), Loss: 0.080, mAP 93.88%
[71/160] 44400), Loss: 0.035, mAP 94.50%
[71/160] 44500), Loss: 0.101, mAP 93.13%
Saved: checkpoints/
TESTING: 44517), mAP 94.76%
Learning Rate 0.001000
[72/160] 44600), Loss: 0.050, mAP 95.56%
[72/160] 44700), Loss: 0.053, mAP 95.15%
[72/160] 44800), Loss: 0.083, mAP 95.03%
[72/160] 44900), Loss: 0.071, mAP 94.95%
[72/160] 45000), Loss: 0.081, mAP 93.46%
[72/160] 45100), Loss: 0.047, mAP 92.49%
Learning Rate 0.001000
[73/160] 45200), Loss: 0.114, mAP 94.44%
[73/160] 45300), Loss: 0.130, mAP 94.26%
[73/160] 45400), Loss: 0.086, mAP 95.27%
[73/160] 45500), Loss: 0.098, mAP 94.65%
[73/160] 45600), Loss: 0.026, mAP 94.48%
[73/160] 45700), Loss: 0.057, mAP 95.29%
Learning Rate 0.001000
[74/160] 45800), Loss: 0.045, mAP 93.46%
[74/160] 45900), Loss: 0.038, mAP 93.12%
[74/160] 46000), Loss: 0.043, mAP 96.04%
[74/160] 46100), Loss: 0.022, mAP 93.97%
[74/160] 46200), Loss: 0.072, mAP 94.51%
[74/160] 46300), Loss: 0.049, mAP 94.03%
Learning Rate 0.001000
[75/160] 46400), Loss: 0.061, mAP 93.92%
[75/160] 46500), Loss: 0.047, mAP 95.25%
[75/160] 46600), Loss: 0.048, mAP 95.64%
[75/160] 46700), Loss: 0.032, mAP 95.41%
[75/160] 46800), Loss: 0.108, mAP 93.51%
[75/160] 46900), Loss: 0.041, mAP 97.52%
[75/160] 47000), Loss: 0.050, mAP 94.80%
Learning Rate 0.001000
[76/160] 47100), Loss: 0.054, mAP 94.83%
[76/160] 47200), Loss: 0.034, mAP 95.34%
[76/160] 47300), Loss: 0.020, mAP 95.44%
[76/160] 47400), Loss: 0.038, mAP 96.33%
[76/160] 47500), Loss: 0.048, mAP 95.20%
[76/160] 47600), Loss: 0.046, mAP 96.11%
Saved: checkpoints/
TESTING: 47652), mAP 94.69%
Learning Rate 0.001000
[77/160] 47700), Loss: 0.070, mAP 93.18%
[77/160] 47800), Loss: 0.068, mAP 90.94%
[77/160] 47900), Loss: 0.060, mAP 95.96%
[77/160] 48000), Loss: 0.020, mAP 95.86%
[77/160] 48100), Loss: 0.049, mAP 95.85%
[77/160] 48200), Loss: 0.034, mAP 94.86%
Learning Rate 0.001000
[78/160] 48300), Loss: 0.029, mAP 94.98%
[78/160] 48400), Loss: 0.039, mAP 97.54%
[78/160] 48500), Loss: 0.050, mAP 96.91%
[78/160] 48600), Loss: 0.103, mAP 94.67%
[78/160] 48700), Loss: 0.037, mAP 96.34%
[78/160] 48800), Loss: 0.083, mAP 95.05%
[78/160] 48900), Loss: 0.028, mAP 95.36%
Learning Rate 0.001000
[79/160] 49000), Loss: 0.077, mAP 96.89%
[79/160] 49100), Loss: 0.062, mAP 95.61%
[79/160] 49200), Loss: 0.048, mAP 94.70%
[79/160] 49300), Loss: 0.054, mAP 96.15%
[79/160] 49400), Loss: 0.090, mAP 94.04%
[79/160] 49500), Loss: 0.049, mAP 95.19%
Learning Rate 0.001000
[80/160] 49600), Loss: 0.045, mAP 95.47%
[80/160] 49700), Loss: 0.158, mAP 94.81%
[80/160] 49800), Loss: 0.067, mAP 91.82%
[80/160] 49900), Loss: 0.069, mAP 92.91%
[80/160] 50000), Loss: 0.038, mAP 94.43%
[80/160] 50100), Loss: 0.093, mAP 95.02%
Learning Rate 0.000100
[81/160] 50200), Loss: 0.065, mAP 97.34%
[81/160] 50300), Loss: 0.050, mAP 95.99%
[81/160] 50400), Loss: 0.059, mAP 93.71%
[81/160] 50500), Loss: 0.074, mAP 96.67%
[81/160] 50600), Loss: 0.053, mAP 95.29%
[81/160] 50700), Loss: 0.115, mAP 94.52%
Saved: checkpoints/
TESTING: 50787), mAP 94.74%
Learning Rate 0.000100
[82/160] 50800), Loss: 0.089, mAP 94.10%
[82/160] 50900), Loss: 0.042, mAP 96.89%
[82/160] 51000), Loss: 0.054, mAP 92.94%
[82/160] 51100), Loss: 0.047, mAP 95.28%
[82/160] 51200), Loss: 0.081, mAP 95.54%
[82/160] 51300), Loss: 0.031, mAP 96.12%
[82/160] 51400), Loss: 0.043, mAP 95.57%
Learning Rate 0.000100
[83/160] 51500), Loss: 0.049, mAP 94.68%
[83/160] 51600), Loss: 0.070, mAP 96.76%
[83/160] 51700), Loss: 0.035, mAP 95.22%
[83/160] 51800), Loss: 0.030, mAP 94.63%
[83/160] 51900), Loss: 0.032, mAP 94.79%
[83/160] 52000), Loss: 0.087, mAP 95.40%
Learning Rate 0.000100
[84/160] 52100), Loss: 0.086, mAP 94.59%
[84/160] 52200), Loss: 0.043, mAP 93.92%
[84/160] 52300), Loss: 0.040, mAP 95.24%
[84/160] 52400), Loss: 0.049, mAP 95.03%
[84/160] 52500), Loss: 0.055, mAP 95.97%
[84/160] 52600), Loss: 0.062, mAP 96.77%
Learning Rate 0.000100
[85/160] 52700), Loss: 0.044, mAP 96.21%
[85/160] 52800), Loss: 0.080, mAP 95.81%
[85/160] 52900), Loss: 0.038, mAP 95.82%
[85/160] 53000), Loss: 0.031, mAP 96.26%
[85/160] 53100), Loss: 0.043, mAP 95.69%
[85/160] 53200), Loss: 0.052, mAP 96.28%
Learning Rate 0.000100
[86/160] 53300), Loss: 0.048, mAP 94.26%
[86/160] 53400), Loss: 0.039, mAP 97.41%
[86/160] 53500), Loss: 0.083, mAP 95.40%
[86/160] 53600), Loss: 0.045, mAP 96.82%
[86/160] 53700), Loss: 0.049, mAP 94.23%
[86/160] 53800), Loss: 0.049, mAP 95.19%
[86/160] 53900), Loss: 0.034, mAP 96.52%
Saved: checkpoints/
TESTING: 53922), mAP 94.79%
Learning Rate 0.000100
[87/160] 54000), Loss: 0.052, mAP 95.85%
[87/160] 54100), Loss: 0.039, mAP 94.06%
[87/160] 54200), Loss: 0.068, mAP 92.77%
[87/160] 54300), Loss: 0.036, mAP 97.63%
[87/160] 54400), Loss: 0.064, mAP 96.98%
[87/160] 54500), Loss: 0.039, mAP 93.19%
Learning Rate 0.000100
[88/160] 54600), Loss: 0.059, mAP 94.38%
[88/160] 54700), Loss: 0.079, mAP 94.65%
[88/160] 54800), Loss: 0.100, mAP 94.10%
[88/160] 54900), Loss: 0.128, mAP 95.99%
[88/160] 55000), Loss: 0.040, mAP 95.62%
[88/160] 55100), Loss: 0.025, mAP 97.01%
Learning Rate 0.000100
[89/160] 55200), Loss: 0.068, mAP 94.88%
[89/160] 55300), Loss: 0.026, mAP 95.07%
[89/160] 55400), Loss: 0.039, mAP 94.88%
[89/160] 55500), Loss: 0.125, mAP 96.79%
[89/160] 55600), Loss: 0.058, mAP 94.41%
[89/160] 55700), Loss: 0.048, mAP 95.82%
[89/160] 55800), Loss: 0.026, mAP 94.70%
Learning Rate 0.000100
[90/160] 55900), Loss: 0.062, mAP 95.05%
[90/160] 56000), Loss: 0.080, mAP 95.96%
[90/160] 56100), Loss: 0.030, mAP 95.39%
[90/160] 56200), Loss: 0.086, mAP 94.81%
[90/160] 56300), Loss: 0.022, mAP 94.52%
[90/160] 56400), Loss: 0.026, mAP 94.93%
Learning Rate 0.000100
[91/160] 56500), Loss: 0.015, mAP 96.09%
[91/160] 56600), Loss: 0.041, mAP 94.20%
[91/160] 56700), Loss: 0.019, mAP 96.61%
[91/160] 56800), Loss: 0.055, mAP 94.66%
[91/160] 56900), Loss: 0.037, mAP 93.67%
[91/160] 57000), Loss: 0.067, mAP 95.76%
Saved: checkpoints/
TESTING: 57057), mAP 94.67%
Learning Rate 0.000100
[92/160] 57100), Loss: 0.045, mAP 97.03%
[92/160] 57200), Loss: 0.042, mAP 94.61%
[92/160] 57300), Loss: 0.045, mAP 95.84%
[92/160] 57400), Loss: 0.048, mAP 93.30%
[92/160] 57500), Loss: 0.024, mAP 94.78%
[92/160] 57600), Loss: 0.013, mAP 95.25%
Learning Rate 0.000100
[93/160] 57700), Loss: 0.030, mAP 96.82%
[93/160] 57800), Loss: 0.076, mAP 96.04%
[93/160] 57900), Loss: 0.070, mAP 95.24%
[93/160] 58000), Loss: 0.050, mAP 93.92%
[93/160] 58100), Loss: 0.038, mAP 95.06%
[93/160] 58200), Loss: 0.030, mAP 96.39%
[93/160] 58300), Loss: 0.084, mAP 98.05%
Learning Rate 0.000100
[94/160] 58400), Loss: 0.051, mAP 95.67%
[94/160] 58500), Loss: 0.067, mAP 97.77%
[94/160] 58600), Loss: 0.040, mAP 93.82%
[94/160] 58700), Loss: 0.087, mAP 94.43%
[94/160] 58800), Loss: 0.016, mAP 94.75%
[94/160] 58900), Loss: 0.085, mAP 95.02%
Learning Rate 0.000100
[95/160] 59000), Loss: 0.025, mAP 94.19%
[95/160] 59100), Loss: 0.077, mAP 95.17%
[95/160] 59200), Loss: 0.051, mAP 94.56%
[95/160] 59300), Loss: 0.023, mAP 95.37%
[95/160] 59400), Loss: 0.026, mAP 95.81%
[95/160] 59500), Loss: 0.035, mAP 97.04%
Learning Rate 0.000100
[96/160] 59600), Loss: 0.025, mAP 97.45%
[96/160] 59700), Loss: 0.057, mAP 96.25%
[96/160] 59800), Loss: 0.078, mAP 95.16%
[96/160] 59900), Loss: 0.167, mAP 95.29%
[96/160] 60000), Loss: 0.045, mAP 95.76%
[96/160] 60100), Loss: 0.067, mAP 94.08%
Saved: checkpoints/
TESTING: 60192), mAP 94.56%
Learning Rate 0.000100
[97/160] 60200), Loss: 0.035, mAP 94.07%
[97/160] 60300), Loss: 0.044, mAP 96.12%
[97/160] 60400), Loss: 0.029, mAP 94.91%
[97/160] 60500), Loss: 0.037, mAP 95.86%
[97/160] 60600), Loss: 0.090, mAP 96.35%
[97/160] 60700), Loss: 0.075, mAP 97.06%
[97/160] 60800), Loss: 0.034, mAP 94.45%
Learning Rate 0.000100
[98/160] 60900), Loss: 0.025, mAP 96.68%
[98/160] 61000), Loss: 0.039, mAP 96.52%
[98/160] 61100), Loss: 0.027, mAP 93.16%
[98/160] 61200), Loss: 0.061, mAP 94.59%
[98/160] 61300), Loss: 0.116, mAP 94.48%
[98/160] 61400), Loss: 0.047, mAP 96.04%
Learning Rate 0.000100
[99/160] 61500), Loss: 0.124, mAP 93.18%
[99/160] 61600), Loss: 0.067, mAP 97.56%
[99/160] 61700), Loss: 0.044, mAP 96.16%
[99/160] 61800), Loss: 0.023, mAP 98.23%
[99/160] 61900), Loss: 0.030, mAP 97.11%
[99/160] 62000), Loss: 0.104, mAP 95.70%
Learning Rate 0.000100
[100/160] 62100), Loss: 0.057, mAP 95.92%
[100/160] 62200), Loss: 0.064, mAP 94.09%
[100/160] 62300), Loss: 0.015, mAP 95.75%
[100/160] 62400), Loss: 0.048, mAP 93.35%
[100/160] 62500), Loss: 0.049, mAP 95.78%
[100/160] 62600), Loss: 0.036, mAP 95.74%
Learning Rate 0.000100
[101/160] 62700), Loss: 0.061, mAP 95.54%
[101/160] 62800), Loss: 0.043, mAP 95.19%
[101/160] 62900), Loss: 0.033, mAP 96.61%
[101/160] 63000), Loss: 0.056, mAP 94.70%
[101/160] 63100), Loss: 0.054, mAP 95.74%
[101/160] 63200), Loss: 0.076, mAP 96.18%
[101/160] 63300), Loss: 0.022, mAP 95.26%
Saved: checkpoints/
TESTING: 63327), mAP 94.94%
Learning Rate 0.000100
[102/160] 63400), Loss: 0.017, mAP 95.67%
[102/160] 63500), Loss: 0.029, mAP 96.42%
[102/160] 63600), Loss: 0.022, mAP 94.95%
[102/160] 63700), Loss: 0.107, mAP 94.66%
[102/160] 63800), Loss: 0.060, mAP 95.01%
[102/160] 63900), Loss: 0.029, mAP 95.87%
Learning Rate 0.000100
[103/160] 64000), Loss: 0.033, mAP 92.79%
[103/160] 64100), Loss: 0.083, mAP 97.75%
[103/160] 64200), Loss: 0.053, mAP 95.94%
[103/160] 64300), Loss: 0.055, mAP 95.91%
[103/160] 64400), Loss: 0.034, mAP 94.52%
[103/160] 64500), Loss: 0.101, mAP 94.30%
Learning Rate 0.000100
[104/160] 64600), Loss: 0.034, mAP 95.26%
[104/160] 64700), Loss: 0.063, mAP 95.21%
[104/160] 64800), Loss: 0.089, mAP 94.82%
[104/160] 64900), Loss: 0.016, mAP 95.39%
[104/160] 65000), Loss: 0.045, mAP 96.74%
[104/160] 65100), Loss: 0.027, mAP 95.69%
[104/160] 65200), Loss: 0.063, mAP 93.45%
Learning Rate 0.000100
[105/160] 65300), Loss: 0.063, mAP 96.48%
[105/160] 65400), Loss: 0.063, mAP 96.72%
[105/160] 65500), Loss: 0.076, mAP 96.35%
[105/160] 65600), Loss: 0.025, mAP 95.10%
[105/160] 65700), Loss: 0.030, mAP 97.07%
[105/160] 65800), Loss: 0.062, mAP 94.07%
Learning Rate 0.000100
[106/160] 65900), Loss: 0.058, mAP 96.74%
[106/160] 66000), Loss: 0.050, mAP 94.10%
[106/160] 66100), Loss: 0.040, mAP 95.92%
[106/160] 66200), Loss: 0.041, mAP 93.99%
[106/160] 66300), Loss: 0.103, mAP 96.76%
[106/160] 66400), Loss: 0.037, mAP 96.60%
Saved: checkpoints/
TESTING: 66462), mAP 94.70%
Learning Rate 0.000100
[107/160] 66500), Loss: 0.034, mAP 95.25%
[107/160] 66600), Loss: 0.021, mAP 97.07%
[107/160] 66700), Loss: 0.015, mAP 95.30%
[107/160] 66800), Loss: 0.064, mAP 96.09%
[107/160] 66900), Loss: 0.018, mAP 98.15%
[107/160] 67000), Loss: 0.024, mAP 96.50%
Learning Rate 0.000100
[108/160] 67100), Loss: 0.059, mAP 96.92%
[108/160] 67200), Loss: 0.086, mAP 93.34%
[108/160] 67300), Loss: 0.109, mAP 95.42%
[108/160] 67400), Loss: 0.021, mAP 95.51%
[108/160] 67500), Loss: 0.019, mAP 95.16%
[108/160] 67600), Loss: 0.018, mAP 95.47%
[108/160] 67700), Loss: 0.038, mAP 95.76%
Learning Rate 0.000100
[109/160] 67800), Loss: 0.064, mAP 96.63%
[109/160] 67900), Loss: 0.049, mAP 95.64%
[109/160] 68000), Loss: 0.064, mAP 95.24%
[109/160] 68100), Loss: 0.048, mAP 96.14%
[109/160] 68200), Loss: 0.026, mAP 96.36%
[109/160] 68300), Loss: 0.056, mAP 96.68%
Learning Rate 0.000100
[110/160] 68400), Loss: 0.038, mAP 94.93%
[110/160] 68500), Loss: 0.037, mAP 94.39%
[110/160] 68600), Loss: 0.027, mAP 94.76%
[110/160] 68700), Loss: 0.035, mAP 95.98%
[110/160] 68800), Loss: 0.078, mAP 95.78%
[110/160] 68900), Loss: 0.052, mAP 96.83%
Learning Rate 0.000100
[111/160] 69000), Loss: 0.056, mAP 95.60%
[111/160] 69100), Loss: 0.041, mAP 93.85%
[111/160] 69200), Loss: 0.089, mAP 96.04%
[111/160] 69300), Loss: 0.057, mAP 95.07%
[111/160] 69400), Loss: 0.035, mAP 95.85%
[111/160] 69500), Loss: 0.098, mAP 95.53%
Saved: checkpoints/
TESTING: 69597), mAP 94.72%
Learning Rate 0.000100
[112/160] 69600), Loss: 0.058, mAP 97.17%
[112/160] 69700), Loss: 0.068, mAP 96.25%
[112/160] 69800), Loss: 0.066, mAP 95.01%
[112/160] 69900), Loss: 0.022, mAP 96.32%
[112/160] 70000), Loss: 0.033, mAP 96.68%
[112/160] 70100), Loss: 0.040, mAP 95.13%
[112/160] 70200), Loss: 0.053, mAP 95.17%
Learning Rate 0.000100
[113/160] 70300), Loss: 0.108, mAP 95.74%
[113/160] 70400), Loss: 0.055, mAP 96.70%
[113/160] 70500), Loss: 0.057, mAP 95.71%
[113/160] 70600), Loss: 0.036, mAP 97.06%
[113/160] 70700), Loss: 0.033, mAP 93.23%
[113/160] 70800), Loss: 0.065, mAP 95.02%
Learning Rate 0.000100
[114/160] 70900), Loss: 0.094, mAP 95.05%
[114/160] 71000), Loss: 0.064, mAP 94.31%
[114/160] 71100), Loss: 0.067, mAP 96.79%
[114/160] 71200), Loss: 0.052, mAP 93.97%
[114/160] 71300), Loss: 0.066, mAP 95.76%
[114/160] 71400), Loss: 0.033, mAP 96.52%
Learning Rate 0.000100
[115/160] 71500), Loss: 0.094, mAP 95.28%
[115/160] 71600), Loss: 0.027, mAP 97.02%
[115/160] 71700), Loss: 0.047, mAP 95.17%
[115/160] 71800), Loss: 0.036, mAP 95.21%
[115/160] 71900), Loss: 0.058, mAP 96.03%
[115/160] 72000), Loss: 0.023, mAP 96.87%
[115/160] 72100), Loss: 0.020, mAP 96.64%
Learning Rate 0.000100
[116/160] 72200), Loss: 0.072, mAP 96.74%
[116/160] 72300), Loss: 0.012, mAP 96.43%
[116/160] 72400), Loss: 0.044, mAP 96.24%
[116/160] 72500), Loss: 0.060, mAP 96.39%
[116/160] 72600), Loss: 0.040, mAP 93.39%
[116/160] 72700), Loss: 0.028, mAP 96.21%
Saved: checkpoints/
TESTING: 72732), mAP 94.69%
Learning Rate 0.000100
[117/160] 72800), Loss: 0.053, mAP 97.01%
[117/160] 72900), Loss: 0.053, mAP 96.03%
[117/160] 73000), Loss: 0.030, mAP 95.89%
[117/160] 73100), Loss: 0.052, mAP 95.19%
[117/160] 73200), Loss: 0.099, mAP 91.54%
[117/160] 73300), Loss: 0.044, mAP 95.81%
Learning Rate 0.000100
[118/160] 73400), Loss: 0.058, mAP 96.20%
[118/160] 73500), Loss: 0.041, mAP 95.13%
[118/160] 73600), Loss: 0.074, mAP 95.42%
[118/160] 73700), Loss: 0.039, mAP 97.22%
[118/160] 73800), Loss: 0.013, mAP 95.84%
[118/160] 73900), Loss: 0.037, mAP 97.36%
Learning Rate 0.000100
[119/160] 74000), Loss: 0.050, mAP 95.08%
[119/160] 74100), Loss: 0.022, mAP 96.48%
[119/160] 74200), Loss: 0.042, mAP 94.56%
[119/160] 74300), Loss: 0.017, mAP 96.14%
[119/160] 74400), Loss: 0.042, mAP 93.90%
[119/160] 74500), Loss: 0.020, mAP 96.43%
[119/160] 74600), Loss: 0.044, mAP 94.98%
Learning Rate 0.000100
[120/160] 74700), Loss: 0.047, mAP 95.61%
[120/160] 74800), Loss: 0.043, mAP 94.87%
[120/160] 74900), Loss: 0.036, mAP 95.70%
[120/160] 75000), Loss: 0.029, mAP 97.76%
[120/160] 75100), Loss: 0.063, mAP 95.16%
[120/160] 75200), Loss: 0.062, mAP 95.45%
Learning Rate 0.000100
[121/160] 75300), Loss: 0.045, mAP 95.76%
[121/160] 75400), Loss: 0.047, mAP 94.94%
[121/160] 75500), Loss: 0.081, mAP 93.91%
[121/160] 75600), Loss: 0.028, mAP 94.04%
[121/160] 75700), Loss: 0.043, mAP 94.49%
[121/160] 75800), Loss: 0.038, mAP 96.07%
Saved: checkpoints/
TESTING: 75867), mAP 94.57%
Learning Rate 0.000100
[122/160] 75900), Loss: 0.045, mAP 95.22%
[122/160] 76000), Loss: 0.052, mAP 97.13%
[122/160] 76100), Loss: 0.102, mAP 95.86%
[122/160] 76200), Loss: 0.066, mAP 96.82%
[122/160] 76300), Loss: 0.023, mAP 95.39%
[122/160] 76400), Loss: 0.051, mAP 96.61%
Learning Rate 0.000100
[123/160] 76500), Loss: 0.037, mAP 93.75%
[123/160] 76600), Loss: 0.051, mAP 96.30%
[123/160] 76700), Loss: 0.042, mAP 93.95%
[123/160] 76800), Loss: 0.079, mAP 96.50%
[123/160] 76900), Loss: 0.054, mAP 96.52%
[123/160] 77000), Loss: 0.082, mAP 96.84%
[123/160] 77100), Loss: 0.033, mAP 96.58%
Learning Rate 0.000100
[124/160] 77200), Loss: 0.083, mAP 94.28%
[124/160] 77300), Loss: 0.031, mAP 96.83%
[124/160] 77400), Loss: 0.040, mAP 94.43%
[124/160] 77500), Loss: 0.037, mAP 95.77%
[124/160] 77600), Loss: 0.083, mAP 95.30%
[124/160] 77700), Loss: 0.102, mAP 92.21%
Learning Rate 0.000100
[125/160] 77800), Loss: 0.040, mAP 96.51%
[125/160] 77900), Loss: 0.023, mAP 97.67%
[125/160] 78000), Loss: 0.023, mAP 98.04%
[125/160] 78100), Loss: 0.116, mAP 93.73%
[125/160] 78200), Loss: 0.103, mAP 96.76%
[125/160] 78300), Loss: 0.016, mAP 96.33%
Learning Rate 0.000100
[126/160] 78400), Loss: 0.017, mAP 97.24%
[126/160] 78500), Loss: 0.022, mAP 95.00%
[126/160] 78600), Loss: 0.023, mAP 93.36%
[126/160] 78700), Loss: 0.106, mAP 96.53%
[126/160] 78800), Loss: 0.045, mAP 94.91%
[126/160] 78900), Loss: 0.077, mAP 93.35%
[126/160] 79000), Loss: 0.049, mAP 95.59%
Saved: checkpoints/
TESTING: 79002), mAP 94.57%
Learning Rate 0.000100
[127/160] 79100), Loss: 0.084, mAP 96.39%
[127/160] 79200), Loss: 0.059, mAP 96.39%
[127/160] 79300), Loss: 0.045, mAP 95.90%
[127/160] 79400), Loss: 0.022, mAP 95.87%
[127/160] 79500), Loss: 0.074, mAP 94.74%
[127/160] 79600), Loss: 0.032, mAP 93.39%
Learning Rate 0.000100
[128/160] 79700), Loss: 0.011, mAP 96.52%
[128/160] 79800), Loss: 0.019, mAP 95.94%
[128/160] 79900), Loss: 0.018, mAP 96.26%
[128/160] 80000), Loss: 0.094, mAP 96.69%
[128/160] 80100), Loss: 0.034, mAP 94.53%
[128/160] 80200), Loss: 0.050, mAP 94.19%
Learning Rate 0.000100
[129/160] 80300), Loss: 0.056, mAP 96.97%
[129/160] 80400), Loss: 0.088, mAP 96.39%
[129/160] 80500), Loss: 0.058, mAP 95.28%
[129/160] 80600), Loss: 0.070, mAP 95.84%
[129/160] 80700), Loss: 0.025, mAP 97.61%
[129/160] 80800), Loss: 0.050, mAP 96.12%
Learning Rate 0.000100
[130/160] 80900), Loss: 0.027, mAP 96.70%
[130/160] 81000), Loss: 0.067, mAP 93.30%
[130/160] 81100), Loss: 0.051, mAP 98.14%
[130/160] 81200), Loss: 0.080, mAP 97.38%
[130/160] 81300), Loss: 0.035, mAP 96.90%
[130/160] 81400), Loss: 0.037, mAP 95.96%
[130/160] 81500), Loss: 0.041, mAP 93.95%
Learning Rate 0.000100
[131/160] 81600), Loss: 0.027, mAP 96.36%
[131/160] 81700), Loss: 0.052, mAP 90.33%
[131/160] 81800), Loss: 0.052, mAP 95.08%
[131/160] 81900), Loss: 0.021, mAP 95.73%
[131/160] 82000), Loss: 0.107, mAP 95.70%
[131/160] 82100), Loss: 0.049, mAP 95.41%
Saved: checkpoints/
TESTING: 82137), mAP 94.61%
Learning Rate 0.000100
[132/160] 82200), Loss: 0.031, mAP 94.98%
[132/160] 82300), Loss: 0.045, mAP 94.84%
[132/160] 82400), Loss: 0.009, mAP 94.98%
[132/160] 82500), Loss: 0.044, mAP 94.49%
[132/160] 82600), Loss: 0.071, mAP 96.67%
[132/160] 82700), Loss: 0.044, mAP 93.47%
Learning Rate 0.000100
[133/160] 82800), Loss: 0.047, mAP 94.60%
[133/160] 82900), Loss: 0.071, mAP 94.24%
[133/160] 83000), Loss: 0.015, mAP 96.97%
[133/160] 83100), Loss: 0.052, mAP 96.17%
[133/160] 83200), Loss: 0.060, mAP 94.08%
[133/160] 83300), Loss: 0.050, mAP 96.28%
Learning Rate 0.000100
[134/160] 83400), Loss: 0.092, mAP 96.21%
[134/160] 83500), Loss: 0.034, mAP 95.79%
[134/160] 83600), Loss: 0.025, mAP 96.79%
[134/160] 83700), Loss: 0.039, mAP 94.01%
[134/160] 83800), Loss: 0.052, mAP 96.28%
[134/160] 83900), Loss: 0.028, mAP 96.70%
[134/160] 84000), Loss: 0.042, mAP 95.81%
Learning Rate 0.000100
[135/160] 84100), Loss: 0.046, mAP 93.23%
[135/160] 84200), Loss: 0.037, mAP 94.17%
[135/160] 84300), Loss: 0.021, mAP 97.42%
[135/160] 84400), Loss: 0.020, mAP 95.65%
[135/160] 84500), Loss: 0.054, mAP 95.67%
[135/160] 84600), Loss: 0.021, mAP 94.99%
Learning Rate 0.000100
[136/160] 84700), Loss: 0.089, mAP 94.10%
[136/160] 84800), Loss: 0.116, mAP 96.50%
[136/160] 84900), Loss: 0.048, mAP 96.17%
[136/160] 85000), Loss: 0.034, mAP 95.74%
[136/160] 85100), Loss: 0.053, mAP 96.32%
[136/160] 85200), Loss: 0.025, mAP 94.59%
Saved: checkpoints/
TESTING: 85272), mAP 94.85%
Learning Rate 0.000100
[137/160] 85300), Loss: 0.105, mAP 94.40%
[137/160] 85400), Loss: 0.034, mAP 95.86%
[137/160] 85500), Loss: 0.022, mAP 96.32%
[137/160] 85600), Loss: 0.020, mAP 97.51%
[137/160] 85700), Loss: 0.038, mAP 93.32%
[137/160] 85800), Loss: 0.068, mAP 96.08%
Learning Rate 0.000100
[138/160] 85900), Loss: 0.079, mAP 98.16%
[138/160] 86000), Loss: 0.023, mAP 95.09%
[138/160] 86100), Loss: 0.038, mAP 97.19%
[138/160] 86200), Loss: 0.026, mAP 95.28%
[138/160] 86300), Loss: 0.020, mAP 96.07%
[138/160] 86400), Loss: 0.042, mAP 95.93%
[138/160] 86500), Loss: 0.043, mAP 95.36%
Learning Rate 0.000100
[139/160] 86600), Loss: 0.024, mAP 96.16%
[139/160] 86700), Loss: 0.020, mAP 97.01%
[139/160] 86800), Loss: 0.072, mAP 95.04%
[139/160] 86900), Loss: 0.041, mAP 94.39%
[139/160] 87000), Loss: 0.045, mAP 96.76%
[139/160] 87100), Loss: 0.043, mAP 96.25%
Learning Rate 0.000100
[140/160] 87200), Loss: 0.033, mAP 96.04%
[140/160] 87300), Loss: 0.045, mAP 96.37%
[140/160] 87400), Loss: 0.061, mAP 94.80%
[140/160] 87500), Loss: 0.029, mAP 94.92%
[140/160] 87600), Loss: 0.040, mAP 96.26%
[140/160] 87700), Loss: 0.034, mAP 94.71%
Learning Rate 0.000100
[141/160] 87800), Loss: 0.026, mAP 95.68%
[141/160] 87900), Loss: 0.014, mAP 92.86%
[141/160] 88000), Loss: 0.090, mAP 95.69%
[141/160] 88100), Loss: 0.044, mAP 94.99%
[141/160] 88200), Loss: 0.021, mAP 97.08%
[141/160] 88300), Loss: 0.050, mAP 97.81%
[141/160] 88400), Loss: 0.076, mAP 95.53%
Saved: checkpoints/
TESTING: 88407), mAP 94.84%
Learning Rate 0.000100
[142/160] 88500), Loss: 0.047, mAP 96.05%
[142/160] 88600), Loss: 0.022, mAP 95.19%
[142/160] 88700), Loss: 0.033, mAP 94.64%
[142/160] 88800), Loss: 0.050, mAP 95.87%
[142/160] 88900), Loss: 0.067, mAP 96.74%
[142/160] 89000), Loss: 0.045, mAP 95.80%
Learning Rate 0.000100
[143/160] 89100), Loss: 0.082, mAP 96.45%
[143/160] 89200), Loss: 0.089, mAP 96.51%
[143/160] 89300), Loss: 0.020, mAP 91.92%
[143/160] 89400), Loss: 0.061, mAP 95.16%
[143/160] 89500), Loss: 0.038, mAP 95.46%
[143/160] 89600), Loss: 0.040, mAP 97.25%
Learning Rate 0.000100
[144/160] 89700), Loss: 0.039, mAP 95.05%
[144/160] 89800), Loss: 0.076, mAP 96.31%
[144/160] 89900), Loss: 0.024, mAP 96.62%
[144/160] 90000), Loss: 0.109, mAP 95.69%
[144/160] 90100), Loss: 0.032, mAP 95.63%
[144/160] 90200), Loss: 0.141, mAP 95.57%
Learning Rate 0.000100
[145/160] 90300), Loss: 0.021, mAP 96.59%
[145/160] 90400), Loss: 0.035, mAP 97.18%
[145/160] 90500), Loss: 0.024, mAP 97.01%
[145/160] 90600), Loss: 0.066, mAP 94.02%
[145/160] 90700), Loss: 0.052, mAP 97.74%
[145/160] 90800), Loss: 0.051, mAP 97.50%
[145/160] 90900), Loss: 0.029, mAP 95.15%
Learning Rate 0.000100
[146/160] 91000), Loss: 0.014, mAP 96.08%
[146/160] 91100), Loss: 0.017, mAP 96.15%
[146/160] 91200), Loss: 0.041, mAP 98.55%
[146/160] 91300), Loss: 0.017, mAP 95.81%
[146/160] 91400), Loss: 0.057, mAP 95.16%
[146/160] 91500), Loss: 0.025, mAP 94.62%
Saved: checkpoints/
TESTING: 91542), mAP 94.81%
Learning Rate 0.000100
[147/160] 91600), Loss: 0.045, mAP 95.58%
[147/160] 91700), Loss: 0.023, mAP 95.30%
[147/160] 91800), Loss: 0.043, mAP 95.89%
[147/160] 91900), Loss: 0.045, mAP 95.74%
[147/160] 92000), Loss: 0.023, mAP 95.81%
[147/160] 92100), Loss: 0.031, mAP 95.71%
Learning Rate 0.000100
[148/160] 92200), Loss: 0.064, mAP 93.44%
[148/160] 92300), Loss: 0.032, mAP 97.15%
[148/160] 92400), Loss: 0.015, mAP 95.20%
[148/160] 92500), Loss: 0.014, mAP 94.93%
[148/160] 92600), Loss: 0.022, mAP 96.71%
[148/160] 92700), Loss: 0.043, mAP 98.15%
Learning Rate 0.000100
[149/160] 92800), Loss: 0.083, mAP 94.26%
[149/160] 92900), Loss: 0.021, mAP 94.85%
[149/160] 93000), Loss: 0.015, mAP 97.30%
[149/160] 93100), Loss: 0.087, mAP 95.80%
[149/160] 93200), Loss: 0.038, mAP 95.54%
[149/160] 93300), Loss: 0.015, mAP 96.42%
[149/160] 93400), Loss: 0.067, mAP 97.13%
Learning Rate 0.000100
[150/160] 93500), Loss: 0.054, mAP 96.65%
[150/160] 93600), Loss: 0.035, mAP 96.79%
[150/160] 93700), Loss: 0.061, mAP 95.32%
[150/160] 93800), Loss: 0.090, mAP 94.58%
[150/160] 93900), Loss: 0.031, mAP 96.70%
[150/160] 94000), Loss: 0.151, mAP 94.10%
Learning Rate 0.000100
[151/160] 94100), Loss: 0.020, mAP 96.97%
[151/160] 94200), Loss: 0.038, mAP 95.06%
[151/160] 94300), Loss: 0.054, mAP 96.28%
[151/160] 94400), Loss: 0.051, mAP 97.60%
[151/160] 94500), Loss: 0.036, mAP 96.76%
[151/160] 94600), Loss: 0.067, mAP 96.11%
Saved: checkpoints/
TESTING: 94677), mAP 94.67%
Learning Rate 0.000100
[152/160] 94700), Loss: 0.033, mAP 94.83%
[152/160] 94800), Loss: 0.039, mAP 96.45%
[152/160] 94900), Loss: 0.066, mAP 97.49%
[152/160] 95000), Loss: 0.098, mAP 96.22%
[152/160] 95100), Loss: 0.058, mAP 96.78%
[152/160] 95200), Loss: 0.019, mAP 96.57%
[152/160] 95300), Loss: 0.050, mAP 95.51%
Learning Rate 0.000100
[153/160] 95400), Loss: 0.045, mAP 96.95%
[153/160] 95500), Loss: 0.044, mAP 96.45%
[153/160] 95600), Loss: 0.060, mAP 95.70%
[153/160] 95700), Loss: 0.046, mAP 96.19%
[153/160] 95800), Loss: 0.015, mAP 96.85%
[153/160] 95900), Loss: 0.038, mAP 96.57%
Learning Rate 0.000100
[154/160] 96000), Loss: 0.044, mAP 97.48%
[154/160] 96100), Loss: 0.031, mAP 94.54%
[154/160] 96200), Loss: 0.025, mAP 95.99%
[154/160] 96300), Loss: 0.026, mAP 96.07%
[154/160] 96400), Loss: 0.049, mAP 96.25%
[154/160] 96500), Loss: 0.040, mAP 96.03%
Learning Rate 0.000100
[155/160] 96600), Loss: 0.039, mAP 96.23%
[155/160] 96700), Loss: 0.056, mAP 96.77%
[155/160] 96800), Loss: 0.021, mAP 96.65%
[155/160] 96900), Loss: 0.027, mAP 94.46%
[155/160] 97000), Loss: 0.022, mAP 95.45%
[155/160] 97100), Loss: 0.043, mAP 95.75%
Learning Rate 0.000100
[156/160] 97200), Loss: 0.017, mAP 94.30%
[156/160] 97300), Loss: 0.077, mAP 95.14%
[156/160] 97400), Loss: 0.022, mAP 97.43%
[156/160] 97500), Loss: 0.068, mAP 94.42%
[156/160] 97600), Loss: 0.029, mAP 95.17%
[156/160] 97700), Loss: 0.023, mAP 95.17%
[156/160] 97800), Loss: 0.050, mAP 94.83%
Saved: checkpoints/
TESTING: 97812), mAP 94.50%
Learning Rate 0.000100
[157/160] 97900), Loss: 0.033, mAP 96.78%
[157/160] 98000), Loss: 0.025, mAP 96.41%
[157/160] 98100), Loss: 0.052, mAP 96.25%
[157/160] 98200), Loss: 0.081, mAP 97.12%
[157/160] 98300), Loss: 0.092, mAP 96.38%
[157/160] 98400), Loss: 0.034, mAP 97.08%
Learning Rate 0.000100
[158/160] 98500), Loss: 0.077, mAP 97.77%
[158/160] 98600), Loss: 0.063, mAP 94.25%
[158/160] 98700), Loss: 0.033, mAP 96.60%
[158/160] 98800), Loss: 0.053, mAP 94.62%
[158/160] 98900), Loss: 0.025, mAP 96.57%
[158/160] 99000), Loss: 0.024, mAP 95.19%
Learning Rate 0.000100
[159/160] 99100), Loss: 0.040, mAP 96.74%
[159/160] 99200), Loss: 0.055, mAP 96.97%
[159/160] 99300), Loss: 0.099, mAP 93.65%
[159/160] 99400), Loss: 0.030, mAP 95.50%
[159/160] 99500), Loss: 0.112, mAP 95.42%
[159/160] 99600), Loss: 0.060, mAP 94.76%
Learning Rate 0.000100
[160/160] 99700), Loss: 0.035, mAP 96.17%
[160/160] 99800), Loss: 0.023, mAP 97.16%
[160/160] 99900), Loss: 0.060, mAP 95.55%
[160/160] 100000), Loss: 0.059, mAP 93.51%
[160/160] 100100), Loss: 0.047, mAP 95.18%
[160/160] 100200), Loss: 0.056, mAP 94.37%
[160/160] 100300), Loss: 0.054, mAP 94.96%

Process finished with exit code 0
